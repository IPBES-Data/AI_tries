---
title: "AI Tries"
format: html
params:
  corpus: !expr file.path(".", "..", "Assessments", "Transformative Change", "IPBES_TCA_Corpus", "ch5_subsidies_reform", "data", "corpus")
  n_samples: 20
  rand_seed: 14
---  

# Introduction

Here I will try AI stuff, mainly using [Ollama](https://github.com/ollama/ollama)

Here are some links in no particular order:

- [https://towardsdatascience.com/running-llama-2-on-cpu-inference-for-document-q-a-3d636037a3d8](https://towardsdatascience.com/running-llama-2-on-cpu-inference-for-document-q-a-3d636037a3d8)

## General info about Llama trsaining
- [datacamp](https://www.datacamp.com/tutorial/llama3-fine-tuning-locally)
- [hugginface](https://huggingface.co/blog/stackllama)

# Setup

```{r}
#| label: setup
#|

if (!require(pak)) {
  pak::pkg_install("pak")
}

if (!require(ollamar)) {
  pak::pkg_install("ollamar")
}
library(ollamar)

library(dplyr)
library(tictoc)
library(pbapply)
library(httr2)
try(
  params <- rmarkdown::yaml_front_matter("~/Documents_Local/git/IPBES_data_tsu/AI Tries/README.qmd")$params,
  silent = TRUE
)
```

# Get papers

I am using a subsample of n random papers from the the IPBES TCA subsidies reform corpus, published after 2000.

```{r}
#| label: get_paper

set.seed(params$rand_seed)

fn <- file.path(".", "data", "papers.rds")
if (file.exists(fn)) {
  papers <- readRDS(fn)
} else {
  papers <- params$corpus |>
    IPBES.R::read_corpus() |>
    dplyr::filter(
      publication_year > 2000,
    ) |>
    dplyr::select(
      id,
      doi,
      title = display_name,
      abstract = ab
    ) |>
    dplyr::slice_sample(
      n = params$n_samples
    ) |>
    dplyr::collect()

  saveRDS(papers, fn)
}
```

## Summarizing abstracts 

Based on [Use R to prompt a local LLM with ollamar](https://blog.stephenturner.us/p/use-r-to-prompt-a-local-llm-with)


### Preparation
```{r}
#| label: preparation

summarized <- papers |>
  dplyr::select(
    title = title,
    abstract
  ) |>
  mutate(
    abstract = substr(abstract, 1, 3000),
    across(
      everything(),
      trimws
    )
  ) |>
  mutate(
    prompt = paste(
      "\n\nI'm going to give you a paper's title and abstract.",
      "Can you summarize this paper in 2 sentences?",
      "\n\nTitle: ", title, "\n\nAbstract: ", abstract,
      "\n\nOnly return the 2 sentence summary.",
      "\n\nDo not put anything in front or after the summary."
    )
  )

```

### Serial
```{r}
#| label: serial

fn <- file.path(".", "data", "summarized_seriell.rds")

tic()

summarized$response <- pbapply::pblapply(
  summarized$prompt,
  function(x) {
    ollamar::generate(
      model = "llama3.1",
      prompt = x,
      output = "text"
    )
  }
) |>
  unlist()

toc()

saveRDS(summarized, fn)

summarized |>
  select(
    title,
    response
  ) |>
  mutate(
    response = gsub("\n", " ", response)
  ) |>
  knitr::kable()

```

### Parallel
```{r}
#| label: parallel

fn <- file.path(".", "data", "summarized_parallel.rds")

tic()

reqs <- lapply(
  summarized$prompt,
  function(x) {
    ollamar::generate(
      model = "llama3.1",
      prompt = x,
      output = "req"
    )
  }
)

resps <- reqs |>
  httr2::req_perform_parallel(
    progress = TRUE
  )

summarized$response <- sapply(
  resps,
  ollamar::resp_process,
  "text"
)

toc()

saveRDS(summarized, fn)

summarized |>
  select(
    title,
    response
  ) |>
  mutate(
    response = gsub("\n", " ", response)
  ) |>
  knitr::kable()
```

## Sentiment Analysis

Inspired by the sentiment analysis at https://github.com/hauselin/ollama-r/

```{r}
#| label: sentiment_analysis

fn <- file.path(".", "data", "sentiments.rds")

reqs <- lapply(
  1:nrow(papers),
  function(i) {
    paste0(
      "\n\nI give you the title and abstract of a scientific paper.",
      "\n\nYour only task/role is to evaluate the sentiment of these towards subsidies.",
      "\n\nYour response should be a valid json with the following info.",
      "\n\n   id: the id of the paper.",
      "\n\n   sentiment: the identified response. It should be one of the following:'positive' or 'negative', or, if you find no information to evaluate the sentiment of the text, 'unknown'.",
      "\n\n   strength: if sentiment is 'positive' or 'negative', a score from -10 to 10 for the sentiment (-10 most negative, 10 most positive), , otherwise -99 if sentiment is unknown,",
      "\n\n   score: if sentiment is 'positive' or 'negative', a value how confident you are in your assessment, ranging from 0 = 'not confident at all' to 10 = 'very confident', otherwise -99 if sentiment is unknown,",
      "\n\n   explanation: an explanation why you think the sentiment is that way. If the sentiment is 'unknown',",
      "\n\n   summary: a 1 sentence summary of the title and abstract, irrespective of the sentiment.",
      "\n\nDo not put anything in front or behind the valid json.",
      "\n\nDo not halucinate.",
      "\n\nBase tour response only on the information I give you.",
      "\n\nDo not summarise the information.",
      "\n\nThe id is:", papers$id[[i]],
      "\n\nThe titel is:", papers$title[[i]],
      "\n\nThe abstract is:", substr(papers$abstract[[i]], 1, 3000)
    ) |>
      ollamar::generate(
        model = "llama3.1",
        output = "req"
      )
  }
)

tic()

sentiments <- httr2::req_perform_parallel(
  reqs,
  progress = TRUE
) |>
  sapply(
    function(resp) {
      ollamar::resp_process(
        resp,
        output = "text"
      )
    }
  )

toc()

sentiments_df <- lapply(
  sentiments,
  function(resp) {
    jsonlite::fromJSON(
      resp
    )
  }
) |>
  dplyr::bind_rows() |>
  dplyr::mutate(
    strength
  )

sentiments_df[sentiments_df == -99] <- as.integer(NA)

saveRDS(sentiments_df, fn)

sentiments_df |>
  knitr::kable()
```
